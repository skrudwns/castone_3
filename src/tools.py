import os, json, math, requests
import httpx
import asyncio
import datetime
import re 
from typing import List, Any, Dict, Optional, Tuple
import traceback
from itertools import permutations

from langchain_core.tools import tool
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import PromptTemplate, ChatPromptTemplate
from langchain_core.load import dumps, loads
from src.config import LLM, load_faiss_index, GMAPS_CLIENT

# ğŸš¨ [ì¤‘ìš”] ì‚¬ìš©ìê°€ ì œê³µí•œ ì§€ì—­ëª… ì •ê·œí™” ëª¨ë“ˆ ì„í¬íŠ¸
try:
    from src.region_cut_fuzz import normalize_region_name
except ImportError:
    def normalize_region_name(name): return name

# --- [1] LLM ì²´ì¸ ì •ì˜ (ì§€ì—­ ì¶”ì¶œ, ì„¤ëª… ìƒì„±) ---

query_gen_prompt = PromptTemplate.from_template("""
ì—­í• : ë‹¹ì‹ ì€ 'ê²€ìƒ‰ì–´ ìµœì í™” ì „ë¬¸ê°€'ì…ë‹ˆë‹¤.
ëª©í‘œ: ì‚¬ìš©ìì˜ ìš”ì²­ê³¼ ì·¨í–¥ì„ ë¶„ì„í•˜ì—¬, ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê°€ì¥ ì •í™•í•œ ì¥ì†Œë¥¼ ì°¾ì„ ìˆ˜ ìˆëŠ” **3ê°œì˜ ê²€ìƒ‰ ì¿¼ë¦¬**ë¥¼ ìƒì„±í•˜ì„¸ìš”.

[ì…ë ¥ ì •ë³´]
- ì—¬í–‰ì§€/ì§€ì—­: {target_region}
- ì‚¬ìš©ì ê²€ìƒ‰ì–´: {query}
- ì‚¬ìš©ì ì·¨í–¥/ì •ë³´: {user_info}
- ì¹´í…Œê³ ë¦¬ í•„í„°: {category_filter}

[ì§€ì¹¨]
1. ì‚¬ìš©ìì˜ ìì—°ì–´ ë¬¸ì¥(ì·¨í–¥)ì—ì„œ **í•µì‹¬ í‚¤ì›Œë“œ(í˜•ìš©ì‚¬, ëª…ì‚¬)**ë§Œ ì¶”ì¶œí•˜ì„¸ìš”. (ì˜ˆ: "ì¡°ìš©í•œ", "ë·°ë§›ì§‘", "ì¬ì¦ˆ")
2. ì§€ì—­ëª…ê³¼ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¡°í•©í•˜ì—¬ ê²€ìƒ‰ì–´ë¥¼ ë§Œë“œì„¸ìš”.
3. ë‹¤ìŒ 3ê°€ì§€ ê´€ì ì˜ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ì„¸ìš”:
   - ì¿¼ë¦¬ 1: ì§€ì—­ëª… + ì‚¬ìš©ì ê²€ìƒ‰ì–´ (ê¸°ë³¸ ì •í™•ë„ ì¤‘ì‹¬)
   - ì¿¼ë¦¬ 2: ì§€ì—­ëª… + ì‚¬ìš©ì ê²€ìƒ‰ì–´ + ì·¨í–¥ í‚¤ì›Œë“œ (êµ¬ì²´ì  ë‹ˆì¦ˆ ì¤‘ì‹¬)
   - ì¿¼ë¦¬ 3: ì§€ì—­ëª… + ë¶„ìœ„ê¸°/í…Œë§ˆ í‚¤ì›Œë“œ (ê´‘ë²”ìœ„ íƒìƒ‰)
4. ê²°ê³¼ëŠ” ì˜¤ì§ ì‰¼í‘œ(,)ë¡œ êµ¬ë¶„ëœ ë¬¸ìì—´ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª…ì€ ìƒëµí•˜ì„¸ìš”.

[ì˜ˆì‹œ]
ì…ë ¥: ì§€ì—­="ì„œìš¸", ê²€ìƒ‰ì–´="ì¹´í˜", ì·¨í–¥="ì¡°ìš©í•˜ê³  ì‘ì—…í•˜ê¸° ì¢‹ì€ ê³³", í•„í„°="ì¹´í˜"
ì¶œë ¥: ì„œìš¸ ì¹´í˜, ì„œìš¸ ì¡°ìš©í•œ ì‘ì—…í•˜ê¸° ì¢‹ì€ ì¹´í˜, ì„œìš¸ ìŠ¤í„°ë”” ì¹´í˜ ë¶„ìœ„ê¸°
""")

query_gen_chain = query_gen_prompt | LLM | StrOutputParser()


# 1-1. ê²€ìƒ‰ì–´ì—ì„œ í–‰ì •êµ¬ì—­ ì¶”ì¶œ (LLM fallbackìš©)
region_prompt = PromptTemplate.from_template("""
ì—­í• : ë‹¹ì‹ ì€ 'ì§€ëª… ì •ê·œí™” ì „ë¬¸ê°€'ì…ë‹ˆë‹¤.
ëª©í‘œ: ì‚¬ìš©ìì˜ ê²€ìƒ‰ì–´("{query}")ì™€ ì—¬í–‰ ëª©ì ì§€("{destination}")ë¥¼ ë³´ê³ , ê²€ìƒ‰ ëŒ€ìƒì´ ë˜ëŠ” **ì •í™•í•œ í–‰ì •êµ¬ì—­ ëª…ì¹­** í•˜ë‚˜ë§Œ ì¶œë ¥í•˜ì„¸ìš”.

[ê·œì¹™]
1. ê²€ìƒ‰ì–´ì— 'í•´ìš´ëŒ€', 'ì†¡ë„' ê°™ì€ êµ¬ì²´ì  ì§€ëª…ì´ ìˆë‹¤ë©´, í•´ë‹¹ ì§€ëª…ì˜ **ê³µì‹ í–‰ì •êµ¬ì—­ëª…**ì„ ì°¾ìœ¼ì„¸ìš”.
2. ê²€ìƒ‰ì–´ê°€ 'ë§›ì§‘', 'ì¹´í˜' ë“± ì¼ë°˜ ëª…ì‚¬ë¿ì´ë¼ë©´, **ì—¬í–‰ ëª©ì ì§€("{destination}")**ë¥¼ ì •ê·œí™”í•´ì„œ ë°˜í™˜í•˜ì„¸ìš”.
3. **ì ˆëŒ€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”.** ëª¨ë¥´ë©´ "{destination}"ì„ ê·¸ëŒ€ë¡œ ë°˜í™˜í•˜ì„¸ìš”.
4. ë‹µë³€ì—ëŠ” êµ°ë”ë”ê¸° ì—†ì´ **ì˜¤ì§ ì§€ì—­ëª…ë§Œ** ì¶œë ¥í•˜ì„¸ìš”.

[ì˜ˆì‹œ]
- ì…ë ¥: "í•´ìš´ëŒ€ ë§›ì§‘", ëª©ì ì§€: "ë¶€ì‚°" -> ì¶œë ¥: "ë¶€ì‚°ê´‘ì—­ì‹œ í•´ìš´ëŒ€êµ¬"
- ì…ë ¥: "ì„±ì‚°ì¼ì¶œë´‰", ëª©ì ì§€: "ì œì£¼ë„" -> ì¶œë ¥: "ì œì£¼íŠ¹ë³„ìì¹˜ë„ ì„œê·€í¬ì‹œ"
- ì…ë ¥: "ê°•ë‚¨ ì ì‹¬", ëª©ì ì§€: "ì„œìš¸" -> ì¶œë ¥: "ì„œìš¸íŠ¹ë³„ì‹œ ê°•ë‚¨êµ¬"
- ì…ë ¥: "ë§›ì§‘ ì¶”ì²œ", ëª©ì ì§€: "ì—¬ìˆ˜" -> ì¶œë ¥: "ì „ë¼ë‚¨ë„ ì—¬ìˆ˜ì‹œ"
""")
region_chain = region_prompt | LLM | StrOutputParser()

# 1-2. ì‚¬ìš©ì ì •ë³´ ê¸°ë°˜ ì¥ì†Œ ì¶”ì²œì‚¬ ìƒì„± ì²´ì¸
desc_prompt = PromptTemplate.from_template("""
[ìƒí™©]
ì‚¬ìš©ì ì •ë³´: {user_info}
ì¥ì†Œ ì´ë¦„: {place_name}
ì¥ì†Œ íŠ¹ì§•/ë¦¬ë·° ìš”ì•½: {place_data}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì´ ì¥ì†Œê°€ **ì´ ì‚¬ìš©ìì—ê²Œ ì™œ ì¢‹ì€ì§€** ë§¤ë ¥ì ì¸ 1~2ì¤„ì˜ ì¶”ì²œì‚¬ë¥¼ ì‘ì„±í•´ì¤˜.
- ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±.
- ë¬¸ì¥ ëì€ 'í•´ìš”', 'ì¢‹ì•„ìš”' ë“±ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë§ˆë¬´ë¦¬.
""")
desc_chain = desc_prompt | LLM | StrOutputParser()


# --- [2] ì§€ë¦¬/ê±°ë¦¬ ê³„ì‚° í—¬í¼ í•¨ìˆ˜ ---

async def get_coordinates(location_name: str):
    """ì§€ëª…/ì£¼ì†Œ -> ì¢Œí‘œ ë³€í™˜ (Google Maps API)"""
    if not GMAPS_CLIENT: return None, None
    try:
        # API ë¹„ìš© ì ˆì•½ì„ ìœ„í•´ ë„ˆë¬´ ê¸´ ì£¼ì†ŒëŠ” ì ë‹¹íˆ ìë¥´ê±°ë‚˜ ì²˜ë¦¬í•  ìˆ˜ ìˆìŒ
        res = await asyncio.to_thread(GMAPS_CLIENT.geocode, location_name, language='ko')
        if res:
            loc = res[0]['geometry']['location']
            return loc['lat'], loc['lng']
    except Exception as e:
        print(f"DEBUG: ì¢Œí‘œ ë³€í™˜ ì‹¤íŒ¨ ({location_name}): {e}")
    return None, None

def calculate_haversine_distance(lat1, lon1, lat2, lon2):
    """ë‘ ì¢Œí‘œ ê°„ì˜ ì§ì„  ê±°ë¦¬(km) ê³„ì‚° (Pure Python)"""
    try:
        lat1, lon1, lat2, lon2 = map(float, [lat1, lon1, lat2, lon2])
    except (ValueError, TypeError):
        return 9999.0

    R = 6371  # ì§€êµ¬ ë°˜ì§€ë¦„ (km)
    d_lat = math.radians(lat2 - lat1)
    d_lon = math.radians(lon2 - lon1)
    a = math.sin(d_lat / 2) ** 2 + math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) * math.sin(d_lon / 2) ** 2
    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))
    return R * c

def calculate_distance_time(start_lat, start_lng, end_lat, end_lng, mode="driving"):
    """ì¢Œí‘œ ê°„ ë‹¨ìˆœ ì§ì„  ê±°ë¦¬ ë° ì˜ˆìƒ ì‹œê°„ ì¶”ì •"""
    dist = calculate_haversine_distance(start_lat, start_lng, end_lat, end_lng)
    
    speed = 4.0 if mode == "walking" else 30.0
    seconds = int((dist / speed) * 3600)
    
    if seconds < 3600: text = f"{seconds // 60}ë¶„"
    else: text = f"{seconds // 3600}ì‹œê°„ {(seconds % 3600) // 60}ë¶„"
    return dist, seconds, text

async def get_detailed_route(start_place: str, end_place: str, mode="transit", departure_time=None):
    """ìƒì„¸ ê²½ë¡œ ì¡°íšŒ (Google Maps Directions API)"""
    if not GMAPS_CLIENT: 
        print(f"DEBUG: âŒ GMAPS_CLIENTê°€ ì—†ìŠµë‹ˆë‹¤. (API Key í™•ì¸ í•„ìš”)")
        return None
    if mode == "transit" and not departure_time: departure_time = datetime.datetime.now()
    if mode != "transit": departure_time = None

    try:
        print(f"DEBUG: ğŸ—ºï¸ ê²½ë¡œ ê²€ìƒ‰ ìš”ì²­: {start_place} -> {end_place}")
        res = await asyncio.to_thread(
            GMAPS_CLIENT.directions, origin=start_place, destination=end_place,
            mode=mode, departure_time=departure_time, region="KR", language="ko"
        )
        if res:
            route = res[0]['legs'][0]
            steps_summary = []
            for step in route['steps']:
                tm = step['travel_mode']
                if tm == 'TRANSIT':
                    line = step.get('transit_details', {}).get('line', {})
                    name = line.get('short_name') or line.get('name') or "ë²„ìŠ¤"
                    steps_summary.append(f"[{line.get('vehicle', {}).get('name', 'ëŒ€ì¤‘êµí†µ')}] {name}")
                elif tm == 'WALKING': steps_summary.append("ğŸš¶ ë„ë³´")
            
            if not steps_summary: steps_summary.append(f"ì´ë™ ({route['duration']['text']})")

            return {
                "mode": mode, "duration": route['duration']['text'],
                "duration_value": route['duration']['value'], "distance": route['distance']['text'],
                "steps": steps_summary,
                "start_location": route['start_location'], "end_location": route['end_location']
            }
    except Exception as e:
        print(f"DEBUG: âš ï¸ ê²½ë¡œ ê²€ìƒ‰ API ì—ëŸ¬: {e}") # ì—ëŸ¬ ë¡œê·¸ ì¶œë ¥
        return None
    
    # Fallback: ì§ì„  ê±°ë¦¬ ê³„ì‚°
    slat, slng = await get_coordinates(start_place)
    elat, elng = await get_coordinates(end_place)
    if slat and elat:
        dist, sec, txt = calculate_distance_time(slat, slng, elat, elng, mode)
        return {"mode": mode, "duration": txt, "duration_value": sec, "distance": f"{dist:.1f}km", "steps": ["ì§ì„ ê±°ë¦¬"], "start_location": {"lat":slat, "lng":slng}, "end_location": {"lat":elat, "lng":elng}}
    return None

async def resolve_admin_region(query: str, destination: str) -> str:
    """
    [í•µì‹¬ ë¡œì§] "ê´‘ì•ˆë¦¬" -> "ë¶€ì‚°ê´‘ì—­ì‹œ ìˆ˜ì˜êµ¬" ìë™ ë³€í™˜ê¸°
    """
    if not GMAPS_CLIENT: 
        return normalize_region_name(destination)

    search_term = query
    if destination and destination not in query:
        search_term = f"{destination} {query}"
        
    print(f"DEBUG: ğŸ—ºï¸ í–‰ì •êµ¬ì—­ ì‹ë³„ ì‹œë„: '{search_term}'")

    try:
        geocode_res = await asyncio.to_thread(GMAPS_CLIENT.geocode, search_term, language='ko')
        
        if not geocode_res:
            return normalize_region_name(destination)

        loc = geocode_res[0]['geometry']['location']
        lat, lng = loc['lat'], loc['lng']
        
        reverse_res = await asyncio.to_thread(GMAPS_CLIENT.reverse_geocode, (lat, lng), language='ko')
        
        if not reverse_res:
            return normalize_region_name(destination)
            
        comps = reverse_res[0].get('address_components', [])
        level1 = "" 
        level2 = "" 
        
        for c in comps:
            types = c.get('types', [])
            if 'administrative_area_level_1' in types:
                level1 = c.get('long_name', '')
            elif 'sublocality_level_1' in types:
                level2 = c.get('long_name', '')
            elif 'locality' in types and not level2:
                level2 = c.get('long_name', '')

        extracted_region = f"{level1} {level2}".strip()
        
        if extracted_region:
            print(f"DEBUG: âœ… ë³€í™˜ ì„±ê³µ: '{query}' -> '{extracted_region}'")
            return extracted_region
        else:
            return normalize_region_name(destination)

    except Exception as e:
        print(f"DEBUG: í–‰ì •êµ¬ì—­ ë³€í™˜ ì¤‘ ì—ëŸ¬: {e}")
        return normalize_region_name(destination)


# --- [3] í•µì‹¬ ê²€ìƒ‰ ë„êµ¬ (ê²€ìƒ‰ + í•„í„°ë§ + Fallback ë¡œì§) ---

async def _search_docs(query_str: str, k: int = 20):
    """Vector DB ê²€ìƒ‰ ë˜í¼"""
    try:
        print(f"DEBUG: ğŸ” ë²¡í„° DB ê²€ìƒ‰ ì‹œë„: '{query_str}' (k={k})")
        db = load_faiss_index()
        if db is None:
            print("DEBUG: âŒ ë²¡í„° DB ì¸ìŠ¤í„´ìŠ¤ ì—†ìŒ (load_faiss_index returned None)")
            return []
        # If similarity_search is blocking/heavy, run in thread
        results = await asyncio.to_thread(db.similarity_search, query_str, k=k)
        print(f"DEBUG: ğŸ” DB ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜: {len(results)}")
        return results
    except Exception as e:
        print(f"DEBUG: DB ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return []

async def _filter_candidates(docs, target_region: str, exclude_places: List[str], category_filter: str):
    """
    ë©”íƒ€ë°ì´í„° í•„í„°ë§ (ì§€ì—­ëª… + ì¹´í…Œê³ ë¦¬ + ì œì™¸ ì¥ì†Œ)
    - ë” ê´€ëŒ€í•˜ê²Œ ë§¤ì¹­: ì§€ì—­ í† í° ì¤‘ í•˜ë‚˜ë¼ë„ ì£¼ì†Œ/ì´ë¦„ì— í¬í•¨ë˜ë©´ í—ˆìš©
    - ëª¨ë“  ë¹„êµëŠ” ì†Œë¬¸ì ê¸°ì¤€ìœ¼ë¡œ ìˆ˜í–‰
    """
    candidates = []

    # ì•ˆì „í•œ defaults
    if exclude_places is None:
        exclude_places = []
    target_region = (target_region or "").strip()

    # 1. ì§€ì—­ëª… í•„í„° í‚¤ì›Œë“œ ì¤€ë¹„ (ì†Œë¬¸ì)
    target_parts = [p.strip() for p in target_region.split() if p.strip()]
    refined_targets = [re.sub(r'(íŠ¹ë³„ì‹œ|ê´‘ì—­ì‹œ|ë„|ì‹œ|êµ°|êµ¬)$', '', p).lower() for p in target_parts]
    if not refined_targets:
        refined_targets = [p.lower() for p in target_parts]

    print(f"DEBUG: âš™ï¸ í•„í„° ì ìš© - ì§€ì—­í‚¤ì›Œë“œ:{refined_targets} / ì¹´í…Œê³ ë¦¬:{category_filter}")

    for doc in docs:
        name = (doc.metadata.get('ì¥ì†Œëª…') or doc.metadata.get('name') or '').strip()
        address = (doc.metadata.get('ì§€ì—­') or doc.metadata.get('road_address') or doc.metadata.get('address') or '').strip()
        doc_cat = (doc.metadata.get('ì¹´í…Œê³ ë¦¬') or doc.metadata.get('category') or '').strip()

        # ğŸš¨ [í•µì‹¬ ìˆ˜ì •] ë©”íƒ€ë°ì´í„°ê°€ ë¹„ì–´ìˆìœ¼ë©´ page_contentì—ì„œ ì¶”ì¶œ
        # í˜•ì‹: "{ì¥ì†Œëª…}ì€(ëŠ”) {ì§€ì—­}ì— ìœ„ì¹˜í•œ {ì¹´í…Œê³ ë¦¬}ì…ë‹ˆë‹¤."
        if (not name or not address or not doc_cat) and hasattr(doc, 'page_content'):
            content = doc.page_content or ''
            try:
                # ì˜ˆ: "ì œì£¼ë•êµ¬ ê²½ê¸°ê´‘ì£¼ì ì€(ëŠ”) ê²½ê¸°ë„ ê´‘ì£¼ì‹œì— ìœ„ì¹˜í•œ ì‹ë‹¹ ìœ¡ë¥˜,ê³ ê¸°ìš”ë¦¬ì…ë‹ˆë‹¤."
                if 'ì€(ëŠ”)' in content and 'ì— ìœ„ì¹˜í•œ' in content:
                    parts = content.split('ì€(ëŠ”)')
                    if len(parts) >= 2:
                        if not name:
                            name = parts[0].strip()

                        location_part = parts[1].split('ì— ìœ„ì¹˜í•œ')
                        if len(location_part) >= 2:
                            if not address:
                                address = location_part[0].strip()
                            if not doc_cat:
                                cat_part = location_part[1].split('ì…ë‹ˆë‹¤')[0].strip()
                                doc_cat = cat_part
            except:
                pass  # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê·¸ëƒ¥ ë„˜ì–´ê°

        name_l = name.lower()
        address_l = address.lower()

        # A. ì œì™¸ ì¥ì†Œ í•„í„° (ì´ë¦„ ê¸°ë°˜)
        if name in exclude_places or name_l in [e.lower() for e in exclude_places]:
            continue

        # B. ì¹´í…Œê³ ë¦¬ í•„í„° (ì—„ê²© + ìœ ì—°)
        if category_filter:
            cf = category_filter.lower()
            if cf in ("ì‹ë‹¹", "ë§›ì§‘"):
                if not any(x in doc_cat for x in ["ì‹ë‹¹", "ë§›ì§‘", "ìŒì‹ì "]):
                    continue
            elif cf == "ì¹´í˜":
                if not any(x in doc_cat for x in ["ì¹´í˜", "ì»¤í”¼"]):
                    continue
            elif cf == "ê´€ê´‘ì§€":
                if not any(x in doc_cat for x in ["ê´€ê´‘", "ì—¬í–‰", "ëª…ì†Œ"]):
                    continue

        # C. ì§€ì—­ í…ìŠ¤íŠ¸ ë§¤ì¹­ í•„í„° (ì£¼ì†Œ ê¸°ë°˜ìœ¼ë¡œë§Œ ë§¤ì¹­)
        is_match = False
        if not refined_targets:
            is_match = True
        else:
            # ì§€ì—­ í•„í„°ëŠ” ì£¼ì†Œ(address)ë§Œ í™•ì¸ (ì¥ì†Œëª…ì— ì§€ì—­ëª…ì´ í¬í•¨ëœ ê²½ìš° ì˜¤ë§¤ì¹­ ë°©ì§€)
            for token in refined_targets:
                if not token:
                    continue
                if token in address_l:  # ì£¼ì†Œì—ì„œë§Œ ê²€ìƒ‰
                    is_match = True
                    break

        if is_match:
            candidates.append(doc)
            
    print(f"DEBUG: âš™ï¸ í•„í„°ë§ í›„ í›„ë³´ ìˆ˜: {len(candidates)}")
    return candidates

@tool
async def find_and_select_best_place(query: str,
                                    destination: str,
                                    anchor: str = "",
                                    exclude_places: List[str] = [],
                                    user_info: str = "", 
                                    category_filter: str = "") -> str:
    """
    [í•µì‹¬ ë„êµ¬] ìµœì ì˜ ì¥ì†Œ 1ê³³ì„ ë°˜í™˜í•©ë‹ˆë‹¤ + ë¦¬ë·° ì •ë³´ í¬í•¨.
    """
    print(f"\n--- [DEBUG] find_and_select_best_place í˜¸ì¶œ ---")
    
    # 1. ì§€ì—­ ë° ê¸°ì¤€ì  ì„¤ì • (ê°œì„ : ì—¬ëŸ¬ ë°©ì‹ìœ¼ë¡œ resolve ì‹œë„í•˜ì—¬ ë” êµ¬ì²´ì ì¸ ì˜ì—­ ì‚¬ìš©)
    target_region = ""
    try:
        if anchor:
            target_region = await resolve_admin_region(anchor, destination)
            print(f"DEBUG: Anchor ê¸°ë°˜ target_region -> '{target_region}'")
        else:
            # ì‹œë„ 1: ì¿¼ë¦¬ë§Œìœ¼ë¡œ resolve (íŠ¹ì • ì§€ëª… í¬í•¨ì‹œ ë” êµ¬ì²´ì ìœ¼ë¡œ ë‚˜ì˜¬ ìˆ˜ ìˆìŒ)
            resolved_query_region = await resolve_admin_region(query, destination)
            print(f"DEBUG: resolved_query_region -> '{resolved_query_region}'")
            # ì‹œë„ 2: destination + query (ì¼ë°˜ì ìœ¼ë¡œ destinationì„ í¬í•¨í•˜ë©´ ê²€ìƒ‰ ë²”ìœ„ê°€ ëª…í™•í•´ì§)
            if destination:
                resolved_dest_query = await resolve_admin_region(f"{destination} {query}", destination)
            else:
                resolved_dest_query = resolved_query_region
            print(f"DEBUG: resolved_dest_query -> '{resolved_dest_query}'")

            # ìš°ì„ ìˆœìœ„ ê²°ì •: ë” êµ¬ì²´ì ì¸(ë” ë§ì€ í† í°ì„ ê°€ì§„) ì§€ì—­ëª…ì„ ì„ íƒ
            def region_specificity_score(region_str: str):
                if not region_str: return 0
                # tokens count including spaces (e.g., "ì„œìš¸íŠ¹ë³„ì‹œ ê°•ë‚¨êµ¬" -> 2)
                return len([p for p in region_str.split() if p.strip()])

            s_query = region_specificity_score(resolved_query_region)
            s_dest = region_specificity_score(resolved_dest_query)
            # ìš°ì„ : resolved_query_regionì´ ë” êµ¬ì²´ì ì´ë©´ ì„ íƒ, ì•„ë‹ˆë©´ destination+query ê²°ê³¼ ì‚¬ìš©
            if s_query > s_dest:
                target_region = resolved_query_region
            else:
                target_region = resolved_dest_query
            # ë§ˆì§€ë§‰ ë³´ì •: ë¹„ì–´ ìˆìœ¼ë©´ destination ì‚¬ìš©
            if not target_region and destination:
                target_region = destination
            print(f"DEBUG: ì„ íƒëœ target_region -> '{target_region}'")
    except Exception as e:
        print(f"DEBUG: resolve_admin_region ì‹¤íŒ¨: {e}")
        target_region = destination or ""

    target_region = (target_region or "").strip()
    print(f"DEBUG: target_region resolved -> '{target_region}'")

    # ê¸°ì¤€ì (Anchor) ì¢Œí‘œ í™•ë³´ (ê±°ë¦¬ ê³„ì‚°ìš©)
    center_place = anchor if anchor else target_region
    center_lat, center_lng = None, None
    if center_place:
        print(f"DEBUG: ğŸ“ ê¸°ì¤€ì  ì¢Œí‘œ ì¡°íšŒ: '{center_place}'")
        try:
            center_lat, center_lng = await get_coordinates(center_place)
        except Exception as e:
            print(f"DEBUG: ì¢Œí‘œ ì¡°íšŒ ì‹¤íŒ¨: {e}")

    try:
        # A. ì¿¼ë¦¬ ìƒì„±
        generated_queries_str = await query_gen_chain.ainvoke({
            "target_region": target_region,
            "query": query,
            "user_info": user_info,
            "category_filter": category_filter
        })
        # ì‰¼í‘œë¡œ ë¶„ë¦¬í•˜ì—¬ ë¦¬ìŠ¤íŠ¸í™”
        search_queries = [q.strip() for q in generated_queries_str.split(',') if q.strip()]
        print(f"DEBUG: ğŸ§  ìƒì„±ëœ ë©€í‹° ì¿¼ë¦¬: {search_queries}")
        
    except Exception as e:
        print(f"DEBUG: ì¿¼ë¦¬ ìƒì„± ì‹¤íŒ¨({e}) -> ê¸°ë³¸ ì¿¼ë¦¬ ì‚¬ìš©")
        search_queries = [f"{target_region} {query} {category_filter}"]
    # B. ë³‘ë ¬ ê²€ìƒ‰ ì‹¤í–‰ (ëª¨ë“  ì¿¼ë¦¬ì— ëŒ€í•´ ë™ì‹œì— ê²€ìƒ‰)
    # ê° ì¿¼ë¦¬ë‹¹ ìƒìœ„ 50ê°œì”© ê²€ìƒ‰ (ë„ˆë¬´ ë§ìœ¼ë©´ ëŠë ¤ì§€ë¯€ë¡œ ì¡°ì ˆ)
    tasks = [_search_docs(q, k=50) for q in search_queries]
    results_list = await asyncio.gather(*tasks)
    
    # C. ê²°ê³¼ í†µí•© ë° ì¤‘ë³µ ì œê±° (Dedup)
    seen_places = set()
    aggregated_docs = []
    
    for docs in results_list:
        for doc in docs:
            p_name = doc.metadata.get('ì¥ì†Œëª…', '')
            # ì´ë¯¸ ê²°ê³¼ ëª©ë¡ì— ìˆê±°ë‚˜, ì œì™¸ ëª©ë¡ì— ìˆë‹¤ë©´ ìŠ¤í‚µ
            if p_name and p_name not in seen_places and p_name not in exclude_places:
                seen_places.add(p_name)
                aggregated_docs.append(doc)
    
    candidates = await _filter_candidates(aggregated_docs, target_region, exclude_places, category_filter)
    print(f"DEBUG: ğŸ¯ í•„í„°ë§ í›„ í›„ë³´êµ° ìˆ˜: {len(candidates)}")

    if not candidates:
        print(f"DEBUG: âš ï¸ 1ì°¨ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ -> 2ì°¨ ê²€ìƒ‰(ì„ í˜¸ ì œì™¸, ê±°ë¦¬/ì¹´í…Œê³ ë¦¬ ì¤‘ì‹¬) ì „í™˜")
        
        # user_info ì œê±°í•˜ê³  ê¸°ë³¸ ì¿¼ë¦¬ë¡œë§Œ ê²€ìƒ‰
        search_query_v2 = f"{query} {target_region} {category_filter}"
        print(f"DEBUG: ğŸ” 2ì°¨ ê²€ìƒ‰ ì‹œë„: '{search_query_v2}'")
        
        docs_v2 = await _search_docs(search_query_v2, k=30)
        candidates = await _filter_candidates(docs_v2, target_region, exclude_places, category_filter)
        print(f"DEBUG: ğŸ¯ 2ì°¨ í›„ë³´êµ° ìˆ˜: {len(candidates)}")

        # 2ì°¨ ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆë‹¤ë©´, ì´ ì¤‘ "ê°€ì¥ ê°€ê¹Œìš´ ê³³"ì„ ì°¾ê¸° ìœ„í•´ ì¢Œí‘œ ë³€í™˜ ìˆ˜í–‰
        if candidates and center_lat and center_lng:
            print("DEBUG: ğŸ“ í›„ë³´êµ° ìƒìœ„ 5ê°œ ê±°ë¦¬ ê³„ì‚° ë° ìµœë‹¨ê±°ë¦¬ ì •ë ¬ ì‹œì‘")
            
            # API ë¹„ìš© ì ˆì•½ì„ ìœ„í•´ ìƒìœ„ 5ê°œë§Œ ì¢Œí‘œ ë³€í™˜
            top_n_candidates = candidates[:5]
            candidates_with_score = []
            
            for doc in top_n_candidates:
                addr = doc.metadata.get('ì§€ì—­', '').strip()

                # ğŸš¨ ë©”íƒ€ë°ì´í„°ê°€ ë¹„ì–´ìˆìœ¼ë©´ page_contentì—ì„œ ì£¼ì†Œ ì¶”ì¶œ
                if not addr and hasattr(doc, 'page_content'):
                    content = doc.page_content or ''
                    try:
                        if 'ì€(ëŠ”)' in content and 'ì— ìœ„ì¹˜í•œ' in content:
                            parts = content.split('ì€(ëŠ”)')
                            if len(parts) >= 2:
                                location_part = parts[1].split('ì— ìœ„ì¹˜í•œ')
                                if len(location_part) >= 2:
                                    addr = location_part[0].strip()
                    except:
                        pass

                p_lat, p_lng = await get_coordinates(addr)
                
                dist = 9999.0
                if p_lat and p_lng:
                    dist = calculate_haversine_distance(center_lat, center_lng, p_lat, p_lng)
                
                candidates_with_score.append((dist, doc))
            
            # ê±°ë¦¬ìˆœ ì •ë ¬ (ì˜¤ë¦„ì°¨ìˆœ)
            candidates_with_score.sort(key=lambda x: x[0])
            
            # ì •ë ¬ëœ ìˆœì„œëŒ€ë¡œ candidates êµì²´
            candidates = [x[1] for x in candidates_with_score]
            if candidates_with_score:
                 print(f"DEBUG: ğŸ¯ ìµœë‹¨ ê±°ë¦¬ ì¥ì†Œ ì„ ì •: {candidates_with_score[0][0]:.1f}km")

    if not candidates:
        print("DEBUG: âŒ 2ì°¨ ê²€ìƒ‰ê¹Œì§€ ì‹¤íŒ¨. ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ.")
        return json.dumps({"name": "ì¶”ì²œ ì¥ì†Œ ì—†ìŒ", "type": "ì •ë³´ì—†ìŒ", "description": "ì¡°ê±´ì— ë§ëŠ” ì¥ì†Œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.", "reviews": []}, ensure_ascii=False)

    best_doc = candidates[0]
    best_name = best_doc.metadata.get('ì¥ì†Œëª…', '').strip()
    best_address = best_doc.metadata.get('ì§€ì—­', '').strip()
    best_category = best_doc.metadata.get('ì¹´í…Œê³ ë¦¬', '').strip()

    # ğŸš¨ [í•µì‹¬ ìˆ˜ì •] ë©”íƒ€ë°ì´í„°ê°€ ë¹„ì–´ìˆìœ¼ë©´ page_contentì—ì„œ ì¶”ì¶œ
    if (not best_name or not best_address or not best_category) and hasattr(best_doc, 'page_content'):
        content = best_doc.page_content or ''
        try:
            # í˜•ì‹: "{ì¥ì†Œëª…}ì€(ëŠ”) {ì§€ì—­}ì— ìœ„ì¹˜í•œ {ì¹´í…Œê³ ë¦¬}ì…ë‹ˆë‹¤."
            if 'ì€(ëŠ”)' in content and 'ì— ìœ„ì¹˜í•œ' in content:
                parts = content.split('ì€(ëŠ”)')
                if len(parts) >= 2:
                    if not best_name:
                        best_name = parts[0].strip()

                    location_part = parts[1].split('ì— ìœ„ì¹˜í•œ')
                    if len(location_part) >= 2:
                        if not best_address:
                            best_address = location_part[0].strip()
                        if not best_category:
                            cat_part = location_part[1].split('ì…ë‹ˆë‹¤')[0].strip()
                            best_category = cat_part
        except:
            pass

    # Fallback
    if not best_name:
        best_name = 'ì´ë¦„ë¯¸ìƒ'

    # ì„¤ëª… ìƒì„±
    description = await desc_chain.ainvoke({
        "user_info": user_info,
        "place_name": best_name,
        "place_data": best_doc.page_content[:400]
    })

    # âœ¨ [ìƒˆë¡œ ì¶”ê°€] ë¦¬ë·° ë°ì´í„° ì¶”ì¶œ (metadataë‚˜ page_contentì—ì„œ)
    reviews = []
    try:
        # ë°©ë²• 1: metadataì—ì„œ ì§ì ‘ ë¦¬ë·° ì¶”ì¶œ (ìˆìœ¼ë©´)
        if 'reviews' in best_doc.metadata:
            reviews_data = best_doc.metadata.get('reviews', [])
            if isinstance(reviews_data, list):
                reviews = reviews_data[:3]  # ìƒìœ„ 3ê°œë§Œ ì¶”ì¶œ
            elif isinstance(reviews_data, str):
                # ë¬¸ìì—´ í˜•íƒœë¼ë©´ ì¤„ë°”ê¿ˆì´ë‚˜ êµ¬ë¶„ìë¡œ split
                reviews = [r.strip() for r in reviews_data.split('\n') if r.strip()][:3]
        
        # ë°©ë²• 2: page_contentì—ì„œ ë¦¬ë·° í‚¤ì›Œë“œ ì°¾ê¸°
        if not reviews and best_doc.page_content:
            content = best_doc.page_content
            # ë¦¬ë·° ì„¹ì…˜ì´ ìˆëŠ”ì§€ í™•ì¸ (ì˜ˆ: "ë¦¬ë·°:" ì´í›„ í…ìŠ¤íŠ¸)
            if 'ë¦¬ë·°' in content or 'review' in content.lower():
                # ê°„ë‹¨í•˜ê²Œ ë¦¬ë·° ì„¹ì…˜ í›„ ì²« 2-3ë¬¸ì¥ ì¶”ì¶œ
                lines = content.split('\n')
                review_start = False
                temp_reviews = []
                for line in lines:
                    if 'ë¦¬ë·°' in line or 'review' in line.lower():
                        review_start = True
                        continue
                    if review_start and line.strip():
                        temp_reviews.append(line.strip())
                        if len(temp_reviews) >= 2:
                            break
                reviews = temp_reviews
    except Exception as e:
        print(f"DEBUG: ë¦¬ë·° ì¶”ì¶œ ì¤‘ ì—ëŸ¬: {e}")
        reviews = []

    # ë¦¬ë·°ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì„¤ì •
    if not reviews:
        reviews = []

    result_data = {
        "name": best_name,
        "type": best_category if best_category else 'ì¥ì†Œ',
        "description": description.strip(),
        "address": best_address,
        "reviews": reviews,  # âœ¨ [ìƒˆë¡œ ì¶”ê°€] ë¦¬ë·° í•„ë“œ
        "coordinates": None
    }
    
    print(f"âœ… ìµœì¢… ì¶”ì²œ: {best_name} / ë¦¬ë·° ê°œìˆ˜: {len(reviews)}")
    return json.dumps(result_data, ensure_ascii=False)



@tool
async def plan_itinerary_timeline(itinerary: List[Dict]) -> str:
    """
    [ì¼ì • ì •ë¦¬ ë„êµ¬] ì¼ì • ë¦¬ìŠ¤íŠ¸ë¥¼ ë°›ì•„ ì‹œê°„ìˆœ íƒ€ì„ë¼ì¸ ìƒì„±
    """
    print(f"\n--- [DEBUG] plan_itinerary_timeline í˜¸ì¶œ ---")
    places_only = [item for item in itinerary if item.get('type') != 'move']
    
    try:
        from src.scheduler.smart_scheduler import SmartScheduler
        scheduler = SmartScheduler(start_time_str="10:00")
        
        days = sorted(list(set(item.get('day', 1) for item in places_only)))
        final_timeline = []
        
        for day in days:
            day_items = [item for item in places_only if item.get('day', 1) == day]
            day_schedule = await scheduler.plan_day(day_items)
            
            for item in day_schedule:
                item['day'] = day
                if item.get('type') == 'move':
                    detail = item.get('transport_detail', '')
                    min_val = item.get('duration_min', 0)
                    item['duration_text'] = f"ì•½ {min_val}ë¶„ ({detail})" if detail else f"ì•½ {min_val}ë¶„ (ì´ë™)"
                final_timeline.append(item)
                
        return json.dumps(final_timeline, ensure_ascii=False)

    except Exception as e:
        print(f"ERROR: ìŠ¤ì¼€ì¤„ë§ ì‹¤íŒ¨: {e}")
        traceback.print_exc()
        return json.dumps(itinerary, ensure_ascii=False)

def _solve_tsp(duration_matrix, start_fixed, n):
    """TSP ì•Œê³ ë¦¬ì¦˜"""
    min_duration = float('inf')
    best_order_indices = []
    
    indices = list(range(n))
    if start_fixed: indices = list(range(1, n))

    if len(indices) > 8:
        current = 0
        unvisited = set(indices)
        path = [0]
        cost = 0
        while unvisited:
            nxt = min(unvisited, key=lambda i: duration_matrix[current][i])
            cost += duration_matrix[current][nxt]
            path.append(nxt)
            unvisited.remove(nxt)
            current = nxt
        return path, cost

    for p in permutations(indices):
        current_indices = [0] + list(p) if start_fixed else list(p)
        current_dur = sum(duration_matrix[current_indices[i]][current_indices[i+1]] for i in range(len(current_indices)-1))
        if current_dur < min_duration:
            min_duration = current_dur
            best_order_indices = current_indices
            
    return best_order_indices, min_duration

@tool
async def optimize_and_get_routes(places: List[str], start_location: str = "") -> str:
    """ìµœì  ê²½ë¡œ(ìˆœì„œ) ê³„ì‚°"""
    if not GMAPS_CLIENT: return "API í‚¤ ì—†ìŒ"
    all_places = [start_location] + places if start_location else places
    if len(all_places) < 2: return "ì¥ì†Œ ë¶€ì¡±"

    try:
        matrix = await asyncio.to_thread(
            GMAPS_CLIENT.distance_matrix, origins=all_places, destinations=all_places, mode="transit"
        )
        dur_matrix = []
        for row in matrix['rows']:
            vals = [el.get('duration', {}).get('value', 99999) for el in row['elements']]
            dur_matrix.append(vals)
            
        best_indices, _ = await asyncio.to_thread(_solve_tsp, dur_matrix, bool(start_location), len(all_places))
        optimized = [all_places[i] for i in best_indices]
        
        return json.dumps({"optimized_order": optimized}, ensure_ascii=False)
        
    except Exception as e:
        return f"ìµœì í™” ì‹¤íŒ¨: {e}"

@tool
def get_weather_forecast(destination: str, dates: str) -> str:
    """
    ë„ì‹œëª…(destination)ìœ¼ë¡œ ìœ„ë„/ê²½ë„ë¥¼ ì¡°íšŒí•˜ê³ , ê·¸ ì¢Œí‘œë¡œ 5ì¼ ì˜ˆë³´ë¥¼ ì¡°íšŒí•˜ì—¬,
    ì‚¬ìš©ìê°€ ìš”ì²­í•œ ë‚ ì§œ(dates)ì˜ ë‚ ì”¨ë§Œ ìš”ì•½í•´ ë°˜í™˜í•©ë‹ˆë‹¤. (3ë‹¨ê³„ ë‚ ì§œ íŒŒì‹± ì ìš©)
    """
    API_KEY = os.getenv("OWM_API_KEY")
    if not API_KEY:
        return "ì˜¤ë¥˜: OWM_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

    # 1ë‹¨ê³„: Geocoding
    geo_url = "https://api.openweathermap.org/geo/1.0/direct"
    geo_params = {'q': f"{destination},KR", 'limit': 1, 'appid': API_KEY}
    lat, lon = None, None
    try:
        response = requests.get(geo_url, params=geo_params, timeout=5)
        response.raise_for_status()
        geo_data = response.json()
        if geo_data:
            lat = geo_data[0]['lat']
            lon = geo_data[0]['lon']
        else:
            return f"ì˜¤ë¥˜: '{destination}'ì˜ ì¢Œí‘œ(Geocoding)ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    except Exception as e:
        return f"ì˜¤ë¥˜: Geocoding API í˜¸ì¶œ ì¤‘ ë¬¸ì œ ë°œìƒ: {e}"

    # 2ë‹¨ê³„: Forecast
    forecast_url = "https://api.openweathermap.org/data/2.5/forecast"
    forecast_params = {'lat': lat, 'lon': lon, 'appid': API_KEY, 'units': 'metric', 'lang': 'kr'}
    forecasts = None
    try:
        response = requests.get(forecast_url, params=forecast_params, timeout=10)
        response.raise_for_status()
        forecast_data = response.json()
        forecasts = forecast_data.get('list', [])
    except Exception as e:
        return f"ì˜¤ë¥˜: Forecast API í˜¸ì¶œ ì¤‘ ë¬¸ì œ ë°œìƒ: {e}"
    if not forecasts:
        return "ì˜¤ë¥˜: Forecast APIì—ì„œ 'list' ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    # 3ë‹¨ê³„: ë‚ ì§œ í•„í„°ë§ (3-Step íŒŒì‹± ë¡œì§)
    target_date_str = ""
    today = datetime.datetime.now()
    
    try:
        # 1. 'YYYYë…„ Mì›” Dì¼' (ê³µë°± O)
        target_date_obj = datetime.datetime.strptime(dates, "%Yë…„ %mì›” %dì¼")
        target_date_str = target_date_obj.strftime("%Y-%m-%d")
    except ValueError:
        try:
            # 2. 'YYYYë…„MMì›”DDì¼' (ê³µë°± X)
            target_date_obj = datetime.datetime.strptime(dates, "%Yë…„%mì›”%dì¼")
            target_date_str = target_date_obj.strftime("%Y-%m-%d")
        except ValueError:
            try:
                # 3. 'Mì›” Dì¼' (ì—°ë„ ì—†ìŒ)
                target_date_obj = datetime.datetime.strptime(dates, "%mì›” %dì¼")
                target_date_obj = target_date_obj.replace(year=today.year)
                target_date_str = target_date_obj.strftime("%Y-%m-%d")
            except ValueError:
                 # 4. ëª¨ë“  í˜•ì‹ ì‹¤íŒ¨ -> í‚¤ì›Œë“œ ê²€ìƒ‰
                 if "ì£¼ë§" in dates or "í† ìš”ì¼" in dates:
                     days_until_saturday = (5 - today.weekday() + 7) % 7
                     saturday = today + datetime.timedelta(days=days_until_saturday)
                     target_date_str = saturday.strftime("%Y-%m-%d")
                 elif "ë‚´ì¼" in dates:
                     tomorrow = today + datetime.timedelta(days=1)
                     target_date_str = tomorrow.strftime("%Y-%m-%d")
                 else: 
                     tomorrow = today + datetime.timedelta(days=1)
                     target_date_str = tomorrow.strftime("%Y-%m-%d")
    
    # 4ë‹¨ê³„: ê²°ê³¼ ê°€ê³µ
    output_str = f"[{destination} ({target_date_str}) ë‚ ì”¨ ì˜ˆë³´ (OWM)]\n"
    found = False
    for forecast in forecasts:
        if forecast['dt_txt'].startswith(target_date_str):
            time_utc = forecast['dt_txt'].split(' ')[1][:5]
            temp = forecast['main']['temp'] 
            desc = forecast['weather'][0]['description']
            output_str += f"- {time_utc} (UTC): {temp:.1f}â„ƒ, {desc}\n"
            found = True
    
    if not found:
        return f"ì •ë³´: {target_date_str} ë‚ ì§œì˜ ì˜ˆë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (OWMì€ 5ì¼ì¹˜ë§Œ ì œê³µ)"
    
    return output_str


@tool
def confirm_and_download_pdf():
    """ìµœì¢… ìŠ¹ì¸ ë° PDF ë‹¤ìš´ë¡œë“œ í™œì„±í™”"""
    return "PDF ë‹¤ìš´ë¡œë“œ ìŠ¹ì¸ë¨"

@tool
async def delete_place(place_name: str) -> str:
    """ì¼ì •ì—ì„œ íŠ¹ì • ì¥ì†Œë¥¼ ì‚­ì œí•©ë‹ˆë‹¤."""
    return json.dumps({"action": "delete", "place_name": place_name}, ensure_ascii=False)

@tool
async def replace_place(old_place_name: str, query: str, destination: str) -> str:
    """ì¼ì • êµì²´ ë„êµ¬"""
    return json.dumps({"action": "replace", "old": old_place_name, "new_query": query}, ensure_ascii=False)


# --- ë„êµ¬ ë“±ë¡ ---
TOOLS = [
    find_and_select_best_place,
    plan_itinerary_timeline,
    optimize_and_get_routes,
    get_weather_forecast,
    delete_place,
    replace_place,
    confirm_and_download_pdf
]
AVAILABLE_TOOLS = {tool.name: tool for tool in TOOLS}